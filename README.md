# Model Quantization Demo

A proof-of-concept application for demonstrating quantization on large language models (LLAMA 2 7B, 13B) and vision transformer models (DeiT S and B). (The quantization algorithm is TBD.)

## Features

- **Quantization Recommendations** - Suggests optimal quantization procedures
- **Layer Sensitivity Analysis** - Identifies which layers are most sensitive to quantization
- **Performance Benchmarking** - Measures inference speed improvements

## Getting Started

(TBD) For now, fork the repository and open on localhost: from `./quant_project/frontend`, run these commands:

```bash
npm install
npm run dev
```