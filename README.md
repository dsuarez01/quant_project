# 📊 Model Quantization Demo

A proof-of-concept application for demonstrating quantization on large language models (LLAMA 2 7B, 13B) and vision transformer models (DeiT S and B). (The quantization algorithm is TBD.)

## Features

- **🎯 Quantization Recommendations** - Suggests optimal quantization procedures
- **🔍 Layer Sensitivity Analysis** - Identifies which layers are most sensitive to quantization
- **⚡ Performance Benchmarking** - Measures inference speed improvements

## Version Requirements:

- Node.js v18+ (tested on v24.4.0)
- npm v9+ (tested on v11.4.2)  
- Go v1.19+ (tested on v1.23.6)

## Getting Started

(TBD) For now, fork the repository and open on localhost: from `./quant_project/frontend`, run these commands:

```bash
npm install
npm run dev
```
